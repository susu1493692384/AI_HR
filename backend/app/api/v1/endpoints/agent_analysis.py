"""
Agent Analysis API Endpoints
æ™ºèƒ½ä½“åˆ†æç›¸å…³çš„ API ç«¯ç‚¹
"""

import logging
from typing import Optional, List
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel

from app.core.dependencies import get_db, get_current_tenant_id, get_current_tenant_id_optional, get_current_user
from app.application.use_cases.resume_analysis import ResumeAnalysisUseCase
from app.application.schemas.agent_analysis import (
    ResumeAnalysisRequest,
    ResumeAnalysisResponse,
    ConversationCreateRequest,
    SendMessageRequest,
    ConversationDetailResponse,
    Message,
    Conversation,
)
from app.application.services.conversation_service import ConversationService

logger = logging.getLogger(__name__)

router = APIRouter()

# MODULE LOAD TEST LOG - This should appear when the module is first imported
print("=== agent_analysis.py MODULE LOADED === If you see this, the code is active")


# ============================================================================
# ç®€å†åˆ†æç«¯ç‚¹
# ============================================================================

@router.post("/analyze/resume", response_model=ResumeAnalysisResponse)
async def analyze_resume_with_agents(
    request: ResumeAnalysisRequest,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id)
):
    """
    ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ†æç®€å†

    å¹¶è¡Œè°ƒç”¨å››ä¸ªä¸“å®¶æ™ºèƒ½ä½“è¿›è¡Œå¤šç»´åº¦åˆ†æï¼š
    - æŠ€èƒ½åŒ¹é…åº¦ä¸“å®¶
    - å·¥ä½œç»éªŒè¯„ä¼°ä¸“å®¶
    - æ•™è‚²èƒŒæ™¯åˆ†æä¸“å®¶
    - è½¯æŠ€èƒ½è¯„ä¼°ä¸“å®¶

    Args:
        request: åˆ†æè¯·æ±‚ï¼ŒåŒ…å«ç®€å†IDå’ŒèŒä½è¦æ±‚
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        ResumeAnalysisResponse: åˆ†æç»“æœï¼ŒåŒ…å«ç»¼åˆè¯„åˆ†å’Œå„ç»´åº¦è¯¦ç»†åˆ†æ

    Raises:
        HTTPException 400: è¯·æ±‚å‚æ•°é”™è¯¯
        HTTPException 404: ç®€å†ä¸å­˜åœ¨
        HTTPException 500: åˆ†æè¿‡ç¨‹å‡ºé”™
    """
    try:
        logger.info(f"æ”¶åˆ°ç®€å†åˆ†æè¯·æ±‚ï¼Œç®€å†ID: {request.resume_id}, ç§Ÿæˆ·: {tenant_id}")

        # åˆ›å»ºç”¨ä¾‹å®ä¾‹
        use_case = ResumeAnalysisUseCase(db)

        # æ‰§è¡Œåˆ†æ
        result = await use_case.analyze_with_agents(
            request=request,
            tenant_id=tenant_id
        )

        logger.info(f"ç®€å†åˆ†ææˆåŠŸï¼Œè¯„åˆ†: {result.analysis.score}")
        return result

    except ValueError as e:
        logger.error(f"ç®€å†åˆ†æå¤±è´¥ï¼ˆå‚æ•°é”™è¯¯ï¼‰: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"ç®€å†åˆ†æå¤±è´¥ï¼ˆç³»ç»Ÿé”™è¯¯ï¼‰: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ†æå¤±è´¥: {str(e)}"
        )


@router.get("/analyze/{resume_id}", response_model=ResumeAnalysisResponse)
async def get_resume_analysis(
    resume_id: str,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id)
):
    """
    è·å–ç®€å†çš„åˆ†æç»“æœï¼ˆå¦‚æœå·²å­˜åœ¨ï¼‰

    Args:
        resume_id: ç®€å†ID
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        ResumeAnalysisResponse: åˆ†æç»“æœ
    """
    try:
        use_case = ResumeAnalysisUseCase(db)
        resume = await use_case.get_resume_by_id(resume_id)

        if not resume:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ç®€å†ä¸å­˜åœ¨: {resume_id}"
            )

        # TODO: ä»æ•°æ®åº“è·å–å·²ä¿å­˜çš„åˆ†æç»“æœ
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="åˆ†æç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆæ‰§è¡Œåˆ†æ"
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–åˆ†æç»“æœå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å¤±è´¥: {str(e)}"
        )


# ============================================================================
# å¯¹è¯ç®¡ç†ç«¯ç‚¹
# ============================================================================

class ConversationListResponse(BaseModel):
    """å¯¹è¯åˆ—è¡¨å“åº”"""
    items: List[Conversation]
    total: int


class MessageListResponse(BaseModel):
    """æ¶ˆæ¯åˆ—è¡¨å“åº”"""
    items: List[Message]
    total: int


class SendMessageResponse(BaseModel):
    """å‘é€æ¶ˆæ¯å“åº”"""
    message: Message
    conversation_id: str


@router.post("/conversations")
async def create_conversation(
    request: ConversationCreateRequest,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id_optional)
):
    """
    åˆ›å»ºæ–°çš„å¯¹è¯

    Args:
        request: å¯¹è¯åˆ›å»ºè¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        åˆ›å»ºçš„å¯¹è¯ä¿¡æ¯
    """
    try:
        service = ConversationService(db)

        conversation = await service.create_conversation(
            tenant_id=tenant_id,
            user_id=None,  # ä»JWTè·å–
            title=request.title or "æ–°å¯¹è¯",
            resume_id=request.resume_id
        )

        return {
            "id": str(conversation.id),
            "title": conversation.title,
            "resume_id": str(conversation.resume_id) if conversation.resume_id else None,
            "created_at": conversation.created_at.isoformat(),
            "status": conversation.status
        }

    except Exception as e:
        logger.error(f"åˆ›å»ºå¯¹è¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ›å»ºå¤±è´¥: {str(e)}"
        )


async def _extract_report_from_conversation(
    conversation_id: str,
    service: ConversationService
) -> Optional[dict]:
    """ä»å¯¹è¯å†å²ä¸­æå–æŠ¥å‘Šæ•°æ®

    Args:
        conversation_id: å¯¹è¯ID
        service: å¯¹è¯æœåŠ¡

    Returns:
        æŠ¥å‘Šæ•°æ®å­—å…¸ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›None
    """
    import json
    import re

    # è·å–å¯¹è¯å†å²æ¶ˆæ¯
    messages = await service.get_conversation_messages(conversation_id)

    # ä»æœ€æ–°çš„æ¶ˆæ¯å¼€å§‹æŸ¥æ‰¾
    for msg in reversed(messages):
        if msg["role"] == "assistant":
            content = msg["content"]

            # æŸ¥æ‰¾JSONæ ¼å¼çš„æŠ¥å‘Šæ•°æ®
            # å°è¯•1: æŸ¥æ‰¾ ```json ä»£ç å—
            json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                try:
                    report_data = json.loads(json_str)
                    # éªŒè¯æ˜¯å¦æ˜¯æŠ¥å‘Šæ ¼å¼ï¼ˆåŒ…å« overall_score æˆ– dimensionsï¼‰
                    if ("overall_score" in report_data or "dimensions" in report_data or
                        any(key in report_data for key in ["skills", "experience", "education",
                                                            "soft_skills", "stability",
                                                            "work_attitude", "development_potential"])):
                        return report_data
                except json.JSONDecodeError:
                    pass

            # å°è¯•2: æŸ¥æ‰¾ç›´æ¥çš„JSONå¯¹è±¡ï¼ˆä¸å«ä»£ç å—ï¼‰
            # æŸ¥æ‰¾åŒ…å« score å’Œç»´åº¦åçš„æ¨¡å¼
            if any(keyword in content for keyword in ["ç»¼åˆè¯„åˆ†", "å„ç»´åº¦è¯„åˆ†", "æŠ€èƒ½åŒ¹é…åº¦",
                                                      "å·¥ä½œç»éªŒ", "æ•™è‚²èƒŒæ™¯", "è½¯æŠ€èƒ½"]):
                # è¿™çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªæŠ¥å‘Šï¼Œä½†å¯èƒ½ä¸æ˜¯çº¯JSON
                # è¿”å›ä¸€ä¸ªç®€åŒ–çš„æŠ¥å‘Šè¡¨ç¤º
                return {
                    "is_text_report": True,
                    "content": content,
                    "summary": content[:500] + "..." if len(content) > 500 else content
                }

    return None


@router.get("/conversations")
async def list_conversations(
    limit: int = 50,
    offset: int = 0,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id_optional)
):
    """
    è·å–å¯¹è¯åˆ—è¡¨

    Args:
        limit: é™åˆ¶æ•°é‡
        offset: åç§»é‡
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        å¯¹è¯åˆ—è¡¨
    """
    try:
        service = ConversationService(db)

        conversations, total = await service.list_conversations(
            tenant_id=tenant_id,
            limit=limit,
            offset=offset
        )

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        items = []
        for conv in conversations:
            # è·å–æœ€åä¸€æ¡æ¶ˆæ¯
            messages = await service.get_messages(str(conv.id), limit=1)
            last_message = messages[0].content if messages else "æš‚æ— æ¶ˆæ¯"

            # è·å–æ¶ˆæ¯æ•°é‡
            all_messages = await service.get_messages(str(conv.id))
            message_count = len(all_messages)

            items.append({
                "id": str(conv.id),
                "title": conv.title,
                "last_message": last_message[:100],
                "timestamp": conv.created_at.isoformat(),
                "is_starred": False,
                "message_count": message_count,
                "resume_id": str(conv.resume_id) if conv.resume_id else None  # æ·»åŠ  resume_id å­—æ®µ
            })

        return {
            "items": items,
            "total": total
        }

    except Exception as e:
        logger.error(f"è·å–å¯¹è¯åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å¤±è´¥: {str(e)}"
        )


@router.get("/conversations/{conversation_id}")
async def get_conversation(
    conversation_id: str,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id_optional)
):
    """
    è·å–å¯¹è¯è¯¦æƒ…

    Args:
        conversation_id: å¯¹è¯ID
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        å¯¹è¯è¯¦æƒ…
    """
    try:
        service = ConversationService(db)

        conversation = await service.get_conversation(conversation_id, tenant_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å¯¹è¯ä¸å­˜åœ¨: {conversation_id}"
            )

        # è·å–æ¶ˆæ¯åˆ—è¡¨
        messages = await service.get_messages(conversation_id)

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        message_items = []
        for msg in messages:
            message_items.append({
                "id": str(msg.id),
                "conversation_id": str(msg.conversation_id),
                "role": msg.role,
                "content": msg.content,
                "created_at": msg.created_at.isoformat()
            })

        return {
            "conversation": {
                "id": str(conversation.id),
                "title": conversation.title,
                "last_message": message_items[-1]["content"][:100] if message_items else "æš‚æ— æ¶ˆæ¯",
                "timestamp": conversation.created_at.isoformat(),
                "is_starred": False,
                "message_count": len(message_items)
            },
            "messages": message_items
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å¤±è´¥: {str(e)}"
        )


@router.delete("/conversations/{conversation_id}")
async def delete_conversation(
    conversation_id: str,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id_optional)
):
    """
    åˆ é™¤å¯¹è¯

    Args:
        conversation_id: å¯¹è¯ID
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        åˆ é™¤ç»“æœ
    """
    try:
        service = ConversationService(db)

        success = await service.delete_conversation(conversation_id, tenant_id)
        if not success:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å¯¹è¯ä¸å­˜åœ¨: {conversation_id}"
            )

        return {"success": True, "message": "åˆ é™¤æˆåŠŸ"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤å¯¹è¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤å¤±è´¥: {str(e)}"
        )


# ============================================================================
# æ¶ˆæ¯ç«¯ç‚¹
# ============================================================================

@router.post("/conversations/{conversation_id}/messages")
async def send_message(
    conversation_id: str,
    request: SendMessageRequest,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id_optional)
):
    """
    å‘é€æ¶ˆæ¯å¹¶è·å–AIå›å¤

    Args:
        conversation_id: å¯¹è¯ID
        request: æ¶ˆæ¯è¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        AIå›å¤
    """
    try:
        service = ConversationService(db)

        # éªŒè¯å¯¹è¯æ˜¯å¦å­˜åœ¨
        conversation = await service.get_conversation(conversation_id, tenant_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å¯¹è¯ä¸å­˜åœ¨: {conversation_id}"
            )

        # å¤„ç†æ¶ˆæ¯å¹¶ç”ŸæˆAIå›å¤
        ai_reply = await service.process_user_message(
            conversation_id=conversation_id,
            user_message=request.content,
            tenant_id=tenant_id,
            resume_id=request.resume_id or str(conversation.resume_id) if conversation.resume_id else None
        )

        # è·å–æœ€åä¸€æ¡AIæ¶ˆæ¯
        messages = await service.get_messages(conversation_id, limit=1)
        last_message = messages[-1] if messages else None

        return {
            "message": {
                "id": str(last_message.id) if last_message else "",
                "conversation_id": conversation_id,
                "role": "assistant",
                "content": ai_reply,
                "created_at": last_message.created_at.isoformat() if last_message else ""
            },
            "conversation_id": conversation_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å‘é€å¤±è´¥: {str(e)}"
        )


@router.get("/conversations/{conversation_id}/messages")
async def get_messages(
    conversation_id: str,
    limit: int = 100,
    offset: int = 0,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id_optional)
):
    """
    è·å–å¯¹è¯çš„æ¶ˆæ¯å†å²

    Args:
        conversation_id: å¯¹è¯ID
        limit: é™åˆ¶æ•°é‡
        offset: åç§»é‡
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        æ¶ˆæ¯åˆ—è¡¨
    """
    try:
        service = ConversationService(db)

        # éªŒè¯å¯¹è¯æ˜¯å¦å­˜åœ¨
        conversation = await service.get_conversation(conversation_id, tenant_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å¯¹è¯ä¸å­˜åœ¨: {conversation_id}"
            )

        messages = await service.get_messages(conversation_id, limit, offset)

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        items = []
        for msg in messages:
            items.append({
                "id": str(msg.id),
                "conversation_id": str(msg.conversation_id),
                "role": msg.role,
                "content": msg.content,
                "created_at": msg.created_at.isoformat()
            })

        # è·å–æ€»æ•°
        all_messages = await service.get_messages(conversation_id)
        total = len(all_messages)

        return {
            "items": items,
            "total": total
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ¶ˆæ¯å†å²å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å¤±è´¥: {str(e)}"
        )


# ============================================================================
# æµå¼å“åº”ç«¯ç‚¹
# ============================================================================

async def generate_streaming_response(
    conversation_id: str,
    user_message: str,
    tenant_id: str,
    service: ConversationService,
    use_agent: bool = False
):
    """ç”Ÿæˆæµå¼å“åº”

    Args:
        conversation_id: å¯¹è¯ID
        user_message: ç”¨æˆ·æ¶ˆæ¯
        tenant_id: ç§Ÿæˆ·ID
        service: å¯¹è¯æœåŠ¡
        use_agent: æ˜¯å¦ä½¿ç”¨æ™ºèƒ½ä½“æ¨¡å¼
    """
    import json
    from datetime import datetime

    # TEST LOG at the very beginning of the streaming response generator
    print(f"=== generate_streaming_response START === conv_id={conversation_id}, use_agent={use_agent}, message={user_message[:50]}")

    try:
        # 1. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_msg = await service.create_message(
            conversation_id=conversation_id,
            role="user",
            content=user_message
        )

        # å‘é€ç”¨æˆ·æ¶ˆæ¯äº‹ä»¶
        yield f"data: {json.dumps({'type': 'user_message', 'message': {'id': str(user_msg.id), 'role': 'user', 'content': user_message}}, ensure_ascii=False)}\n\n"

        # 2. è·å–å¯¹è¯å†å²
        history = await service.get_conversation_messages(conversation_id)

        # 3. æ ¹æ®æ¨¡å¼é€‰æ‹©å“åº”æ–¹å¼
        print(f"=== MODE SELECTION === use_agent={use_agent}, type={type(use_agent)}")
        if use_agent:
            # æ™ºèƒ½ä½“æ¨¡å¼
            print(f"=== ENTERING AGENT MODE === conversation_id={conversation_id}")
            logger.info(f"ä½¿ç”¨æ™ºèƒ½ä½“æ¨¡å¼å¤„ç†æ¶ˆæ¯: conversation_id={conversation_id}")
            async for chunk in _generate_agent_mode_response(history, conversation_id, tenant_id, service):
                yield chunk
        else:
            # ç®€å•å¯¹è¯æ¨¡å¼
            print(f"=== ENTERING SIMPLE MODE === conversation_id={conversation_id}")
            async for chunk in _generate_simple_mode_response(history, conversation_id, tenant_id, service):
                yield chunk

    except Exception as e:
        logger.error(f"æµå¼å“åº”ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"


async def _generate_simple_mode_response(history, conversation_id: str, tenant_id: str, service):
    """ç”Ÿæˆç®€å•å¯¹è¯å“åº”ï¼ˆç›´æ¥è°ƒç”¨LLMï¼‰"""
    import json

    print(f"=== _generate_simple_mode_response START === conversation_id={conversation_id}")

    system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„HR AIåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è¿›è¡Œç®€å†åˆ†æå’Œæ‹›è˜ç›¸å…³å·¥ä½œã€‚

ä½ çš„èŒè´£ï¼š
1. å›ç­”ç”¨æˆ·å…³äºç®€å†åˆ†æçš„é—®é¢˜
2. æä¾›æ‹›è˜å»ºè®®å’Œæ„è§
3. è§£é‡Šåˆ†æç»“æœçš„å«ä¹‰
4. ååŠ©è¿›è¡Œå€™é€‰äººè¯„ä¼°

è¯·ä¿æŒä¸“ä¸šã€å‹å¥½çš„è¯­æ°”ï¼Œæä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚"""

    # è·å–å…³è”çš„ç®€å†ä¿¡æ¯
    resume_context = ""
    try:
        from uuid import UUID
        from sqlalchemy import select
        from app.infrastructure.database.models import Conversation, Resume

        print(f"[ç®€å•æ¨¡å¼] å¼€å§‹è·å–ç®€å†ä¿¡æ¯ï¼Œconversation_id={conversation_id}")

        conv_query = select(Conversation).where(Conversation.id == UUID(conversation_id))
        conv_result = await service.db.execute(conv_query)
        conversation = conv_result.scalar_one_or_none()

        print(f"[ç®€å•æ¨¡å¼] conversation={conversation is not None}, resume_id={conversation.resume_id if conversation else None}")

        if conversation and conversation.resume_id:
            resume_query = select(Resume).where(Resume.id == conversation.resume_id)
            resume_result = await service.db.execute(resume_query)
            resume = resume_result.scalar_one_or_none()

            print(f"[ç®€å•æ¨¡å¼] resume={resume is not None}, has_parsed={resume.parsed_content is not None if resume else False}")

            if resume:
                # ä¼˜å…ˆä½¿ç”¨ extracted_text (æ€»æ˜¯æœ‰æ•°æ®)
                if resume.extracted_text:
                    resume_context = f"\n\nã€å…³è”ç®€å†ä¿¡æ¯ã€‘\nå€™é€‰äººå§“åï¼š{resume.candidate_name or 'æœªçŸ¥'}\n"
                    resume_context += f"\nç®€å†å†…å®¹ï¼š\n{resume.extracted_text}\n"
                    print(f"[ç®€å•æ¨¡å¼] ä½¿ç”¨extracted_textä½œä¸ºç®€å†ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(resume.extracted_text)}")
                else:
                    # fallback to parsed_content
                    if resume.parsed_content and len(resume.parsed_content) > 0:
                        resume_context = f"\n\nã€å…³è”ç®€å†ä¿¡æ¯ã€‘\nå€™é€‰äººå§“åï¼š{resume.candidate_name or 'æœªçŸ¥'}\n"
                        parsed = resume.parsed_content

                        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æ„åŒ–æ•°æ®ï¼ˆbasic_info, work_experienceç­‰ï¼‰
                        has_structured_data = any(key in parsed for key in ['basic_info', 'work_experience', 'education', 'skills', 'projects'])

                        if has_structured_data:
                            # ä½¿ç”¨ç»“æ„åŒ–æ•°æ®
                            # åŸºæœ¬ä¿¡æ¯
                            if parsed.get('basic_info'):
                                basic = parsed['basic_info']
                                resume_context += f"ç›®æ ‡èŒä½ï¼š{basic.get('target_position', 'æœªæŒ‡å®š')}\n"
                                resume_context += f"å·¥ä½œå¹´é™ï¼š{basic.get('total_experience', 'æœªæŒ‡å®š')}\n"
                                resume_context += f"è”ç³»ç”µè¯ï¼š{basic.get('phone', 'æœªæä¾›')}\n"
                                resume_context += f"é‚®ç®±ï¼š{basic.get('email', 'æœªæä¾›')}\n"

                            # å·¥ä½œç»å†
                            if parsed.get('work_experience'):
                                resume_context += "\nå·¥ä½œç»å†ï¼š\n"
                                for idx, work in enumerate(parsed['work_experience'], 1):
                                    resume_context += f"{idx}. {work.get('company', 'æœªçŸ¥å…¬å¸')} - {work.get('position', 'æœªçŸ¥èŒä½')}\n"
                                    resume_context += f"   æ—¶é—´ï¼š{work.get('start_date', '')} è‡³ {work.get('end_date', 'è‡³ä»Š')}\n"
                                    resume_context += f"   æè¿°ï¼š{work.get('description', 'æš‚æ— æè¿°')}\n"

                            # æ•™è‚²èƒŒæ™¯
                            if parsed.get('education'):
                                resume_context += "\næ•™è‚²èƒŒæ™¯ï¼š\n"
                                for idx, edu in enumerate(parsed['education'], 1):
                                    resume_context += f"{idx}. {edu.get('school', 'æœªçŸ¥å­¦æ ¡')} - {edu.get('major', 'æœªçŸ¥ä¸“ä¸š')}\n"
                                    resume_context += f"   å­¦å†ï¼š{edu.get('degree', 'æœªçŸ¥')}\n"
                                    resume_context += f"   æ—¶é—´ï¼š{edu.get('start_date', '')} è‡³ {edu.get('end_date', '')}\n"

                            # æŠ€èƒ½
                            if parsed.get('skills'):
                                resume_context += "\næŠ€èƒ½åˆ—è¡¨ï¼š\n"
                                skills = parsed['skills']
                                skill_list = [s['name'] if isinstance(s, dict) else s for s in skills]
                                resume_context += f"{', '.join(skill_list)}\n"

                            # é¡¹ç›®ç»éªŒ
                            if parsed.get('projects'):
                                resume_context += "\né¡¹ç›®ç»éªŒï¼š\n"
                                for idx, proj in enumerate(parsed['projects'], 1):
                                    resume_context += f"{idx}. {proj.get('name', 'æœªçŸ¥é¡¹ç›®')}\n"
                                    resume_context += f"   æè¿°ï¼š{proj.get('description', 'æš‚æ— æè¿°')}\n"
                                    resume_context += f"   æŠ€æœ¯æ ˆï¼š{proj.get('tech_stack', 'æœªæŒ‡å®š')}\n"

                            # å®Œæ•´ç®€å†æ•°æ®ï¼ˆä¾›è¯¦ç»†åˆ†æï¼‰
                            resume_context += f"\nå®Œæ•´ç®€å†æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰ï¼š\n{json.dumps(parsed, ensure_ascii=False, indent=2)}\n"

                        print(f"[ç®€å•æ¨¡å¼] å·²åŠ è½½ç®€å†ä¸Šä¸‹æ–‡ï¼Œç®€å†ID: {resume.id}, ä¸Šä¸‹æ–‡é•¿åº¦: {len(resume_context)}")
                    else:
                        print(f"[ç®€å•æ¨¡å¼] ç®€å†æ•°æ®ä¸ºç©º,æ—¢æ²¡æœ‰extracted_textä¹Ÿæ²¡æœ‰parsed_content")
                        resume_context = ""
            else:
                print(f"[ç®€å•æ¨¡å¼] ç®€å†å¯¹è±¡ä¸å­˜åœ¨ï¼Œresume_id={conversation.resume_id if conversation else None}")
        else:
            print(f"[ç®€å•æ¨¡å¼] å¯¹è¯æœªå…³è”ç®€å†æˆ–conversationä¸ºç©º")
    except Exception as e:
        logger.error(f"[ç®€å•æ¨¡å¼] è·å–ç®€å†æ•°æ®å¤±è´¥: {e}", exc_info=True)

    messages = [{"role": "system", "content": system_prompt}]

    # å°†å†å²è®°å½•ä¸­çš„æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯æ›¿æ¢ä¸ºå¸¦æœ‰ç®€å†ä¸Šä¸‹æ–‡çš„ç‰ˆæœ¬
    if history:
        # æ·»åŠ é™¤æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¤–çš„æ‰€æœ‰å†å²æ¶ˆæ¯
        messages.extend(history[:-1] if len(history) > 1 else [])

        # å¤„ç†æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆç”¨æˆ·æ¶ˆæ¯ï¼‰
        last_message = history[-1]
        if last_message.get('role') == 'user':
            # å°†ç®€å†ä¸Šä¸‹æ–‡æ·»åŠ åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­
            enhanced_content = last_message.get('content', '') + resume_context
            messages.append({"role": "user", "content": enhanced_content})
            logger.info(f"[ç®€å•æ¨¡å¼] å·²æ·»åŠ ç®€å†ä¸Šä¸‹æ–‡åˆ°ç”¨æˆ·æ¶ˆæ¯: "
                       f"åŸå§‹é•¿åº¦={len(last_message.get('content', ''))}, "
                       f"ç®€å†ä¸Šä¸‹æ–‡é•¿åº¦={len(resume_context)}, "
                       f"å¢å¼ºåé•¿åº¦={len(enhanced_content)}")
        else:
            messages.extend(history[-1:])  # å¦‚æœä¸æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œç›´æ¥æ·»åŠ 
    else:
        messages.extend(history)

    # è°ƒç”¨LLM
    from app.application.services.llm_service import TenantLLMService, TenantService
    from app.core.config import settings
    from app.core.llm_init import DEFAULT_TENANT_ID
    import os

    # è·å–ç§Ÿæˆ·ä¿¡æ¯
    tenant = await TenantService.get_by_id(service.db, tenant_id)
    model_to_use = settings.DEFAULT_AI_MODEL
    if tenant and tenant.llm_id:
        model_to_use = tenant.llm_id
    elif tenant_id == DEFAULT_TENANT_ID:
        model_to_use = "glm-4@ZHIPU-AI"

    llm_config = await TenantLLMService.get_api_key(
        service.db, tenant_id, model_to_use
    )

    # æ£€æŸ¥APIå¯†é’¥
    api_key = None
    if llm_config and llm_config.api_key:
        api_key = llm_config.api_key
    else:
        api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        error_msg = """æŠ±æ­‰ï¼ŒAIåŠ©æ‰‹æš‚æ—¶æ— æ³•ä½¿ç”¨ã€‚

è¯·å…ˆé…ç½®AIæ¨¡å‹çš„APIå¯†é’¥ï¼š
1. è¿›å…¥ã€ŒAIæ¨¡å‹ç®¡ç†ã€é¡µé¢
2. æ·»åŠ æ‚¨çš„OpenAI APIå¯†é’¥
3. è®¾ç½®é»˜è®¤æ¨¡å‹åå³å¯ä½¿ç”¨"""

        # å‘é€é”™è¯¯æ¶ˆæ¯ä½œä¸ºtokenæµ
        words = error_msg.split()
        accumulated = ""
        for word in words:
            accumulated += word + " "
            yield f"data: {json.dumps({'type': 'token', 'token': word + ' ', 'accumulated': accumulated.strip()}, ensure_ascii=False)}\n\n"

        await service.create_message(
            conversation_id=conversation_id,
            role="assistant",
            content=error_msg
        )
        yield f"data: {json.dumps({'type': 'done', 'message': {'role': 'assistant', 'content': error_msg}}, ensure_ascii=False)}\n\n"
        return

    # è°ƒç”¨LLM - ä½¿ç”¨è¾ƒä½æ¸©åº¦ä½¿å›å¤æ›´ä¸¥è°¨
    if llm_config:
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(
            model=llm_config.llm_name,
            openai_api_key=api_key,
            base_url=llm_config.api_base or None,
            temperature=0.3,
            max_tokens=llm_config.max_tokens or settings.DEFAULT_MAX_TOKENS,
        )
    else:
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(
            model=settings.DEFAULT_AI_MODEL,
            openai_api_key=api_key,
            temperature=0.3,
            max_tokens=settings.DEFAULT_MAX_TOKENS,
        )

    # ç”Ÿæˆå›å¤
    from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

    langchain_messages = []
    for msg in messages:
        if msg["role"] == "system":
            langchain_messages.append(SystemMessage(content=msg["content"]))
        elif msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            langchain_messages.append(AIMessage(content=msg["content"]))

    response = await llm.ainvoke(langchain_messages)
    ai_reply = response.content

    # æ¨¡æ‹Ÿæµå¼è¾“å‡º
    words = ai_reply.split()
    accumulated = ""
    for word in words:
        accumulated += word + " "
        yield f"data: {json.dumps({'type': 'token', 'token': word + ' ', 'accumulated': accumulated.strip()}, ensure_ascii=False)}\n\n"

    # ä¿å­˜AIå›å¤
    await service.create_message(
        conversation_id=conversation_id,
        role="assistant",
        content=ai_reply
    )

    # å‘é€å®Œæˆäº‹ä»¶
    yield f"data: {json.dumps({'type': 'done', 'message': {'role': 'assistant', 'content': ai_reply}}, ensure_ascii=False)}\n\n"


async def _generate_report_based_response(
    user_message: str,
    report_context: dict,
    conversation_id: str,
    tenant_id: str,
    service: ConversationService
):
    """ç”ŸæˆåŸºäºæŠ¥å‘Šçš„å¯¹è¯å“åº”ï¼ˆé™åˆ¶åœ¨æŠ¥å‘Šç›¸å…³èŒƒå›´å†…ï¼‰

    Args:
        user_message: ç”¨æˆ·æ¶ˆæ¯
        report_context: æŠ¥å‘Šä¸Šä¸‹æ–‡æ•°æ®
        conversation_id: å¯¹è¯ID
        tenant_id: ç§Ÿæˆ·ID
        service: å¯¹è¯æœåŠ¡
    """
    import json
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, SystemMessage
    from app.core.config import settings

    logger = logging.getLogger(__name__)

    # æ„å»ºæŠ¥å‘Šæ‘˜è¦
    if report_context.get("is_text_report"):
        # æ–‡æœ¬æ ¼å¼çš„æŠ¥å‘Š
        report_summary = report_context.get("summary", report_context.get("content", ""))
        dimensions_info = "æŠ¥å‘Šå·²ç”Ÿæˆï¼ŒåŒ…å«æŠ€èƒ½åŒ¹é…åº¦ã€å·¥ä½œç»éªŒã€æ•™è‚²èƒŒæ™¯ã€è½¯æŠ€èƒ½ã€ç¨³å®šæ€§ã€å·¥ä½œæ€åº¦ã€å‘å±•æ½œåŠ›ç­‰7ä¸ªç»´åº¦çš„è¯¦ç»†åˆ†æã€‚"
    else:
        # JSONæ ¼å¼çš„æŠ¥å‘Š
        overall_score = report_context.get("overall_score", "N/A")
        dimensions = report_context.get("dimensions", {})

        dimensions_info = "\n".join([
            f"- **{dim_name}**: {dim_data.get('score', 'N/A')}/100 - {dim_data.get('score_reason', '')[:100]}"
            for dim_name, dim_data in list(dimensions.items())[:7]
        ])

        report_summary = f"""**ç»¼åˆè¯„åˆ†**: {overall_score}/100

**å„ç»´åº¦è¯„åˆ†**:
{dimensions_info}"""

    # æ„å»ºé™åˆ¶èŒƒå›´çš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„HR AIåŠ©æ‰‹ï¼Œåˆšåˆšå®Œæˆäº†å€™é€‰äººçš„7ç»´åº¦åˆ†ææŠ¥å‘Šã€‚

**åˆ†ææŠ¥å‘Šæ‘˜è¦**ï¼š
{report_summary}

**é‡è¦ï¼šä½ ç°åœ¨çš„è§’è‰²æ˜¯æŠ¥å‘Šè§£è¯»åŠ©æ‰‹**

ä½ çš„èŒè´£èŒƒå›´ï¼š
1. âœ… è§£é‡ŠæŠ¥å‘Šä¸­çš„è¯„åˆ†ä¾æ®å’Œå…·ä½“å«ä¹‰
2. âœ… è¯´æ˜å¯ä¿¡é™ˆè¿°å’Œéœ€è¦éªŒè¯çš„é™ˆè¿°
3. âœ… è§£è¯»å»ºè®®çš„é¢è¯•é—®é¢˜
4. âœ… æä¾›æ”¹è¿›å»ºè®®å’Œå‘å±•æ–¹å‘
5. âœ… å¸®åŠ©ç”¨æˆ·ç†è§£æŠ¥å‘Šä¸­çš„ä»»ä½•æœ¯è¯­å’Œæ¦‚å¿µ

**è¶…å‡ºèŒƒå›´çš„è¯é¢˜ï¼ˆéœ€ç¤¼è²Œæ‹’ç»ï¼‰**ï¼š
- âŒ è¯¢é—®æ— å…³çš„HRçŸ¥è¯†ï¼ˆå¦‚"ä»€ä¹ˆæ˜¯KPI"ï¼‰
- âŒ è¯¢é—®å…¶ä»–å€™é€‰äººæˆ–èŒä½ä¿¡æ¯
- âŒ è¯·æ±‚é‡æ–°ç”ŸæˆæŠ¥å‘Šï¼ˆæŠ¥å‘Šå·²å›ºå®šï¼‰
- âŒ è¯¢é—®ä¸å½“å‰æŠ¥å‘Šæ— å…³çš„å†…å®¹

**æ‹’ç»è¯æœ¯æ¨¡æ¿**ï¼š
"æŠ±æ­‰ï¼Œæˆ‘å½“å‰çš„è§’è‰²æ˜¯å¸®åŠ©æ‚¨ç†è§£è¿™ä»½å€™é€‰äººåˆ†ææŠ¥å‘Šã€‚å…³äºæŠ¥å‘Šä¸­çš„è¯„åˆ†ã€å»ºè®®æˆ–é¢è¯•é—®é¢˜ï¼Œæˆ‘å¾ˆä¹æ„ä¸ºæ‚¨è§£ç­”ã€‚"
"è¿™ä¸ªé—®é¢˜è¶…å‡ºäº†æŠ¥å‘Šè§£è¯»çš„èŒƒå›´ã€‚æˆ‘å¯ä»¥å¸®æ‚¨åˆ†æå€™é€‰äººçš„[ç»´åº¦]è¯„åˆ†ï¼Œæˆ–è€…è§£é‡ŠæŠ¥å‘Šä¸­çš„ä»»ä½•å†…å®¹ã€‚"

è¯·åŸºäºå¯¹è¯å†å²å’ŒæŠ¥å‘Šå†…å®¹ï¼Œç»™ç”¨æˆ·ä¸€ä¸ªä¸“ä¸šã€å‹å¥½ã€èšç„¦çš„å›å¤ã€‚
"""

    # è·å–LLMé…ç½®
    from app.application.services.llm_service import TenantLLMService, TenantService
    from app.core.config import settings
    from app.core.llm_init import DEFAULT_TENANT_ID
    import os

    # é¦–å…ˆè·å–ç§Ÿæˆ·ä¿¡æ¯ï¼Œçœ‹çœ‹ç§Ÿæˆ·é…ç½®äº†ä»€ä¹ˆé»˜è®¤æ¨¡å‹
    tenant = await TenantService.get_by_id(service.db, tenant_id)

    # ç¡®å®šè¦ä½¿ç”¨çš„æ¨¡å‹
    model_to_use = settings.DEFAULT_AI_MODEL  # é»˜è®¤å€¼
    if tenant and tenant.llm_id:
        model_to_use = tenant.llm_id
    elif tenant_id == DEFAULT_TENANT_ID:
        # å¯¹äºé»˜è®¤ç§Ÿæˆ·ï¼Œå°è¯•ä»åˆå§‹åŒ–é…ç½®è·å–
        model_to_use = "glm-4@ZHIPU-AI"  # æˆ–ä»é…ç½®è¯»å–

    # è·å–ç§Ÿæˆ·çš„LLMé…ç½®
    llm_config = await TenantLLMService.get_api_key(
        service.db, tenant_id, model_to_use
    )

    # æ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥é…ç½®
    api_key = None
    if llm_config and llm_config.api_key:
        api_key = llm_config.api_key
    else:
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        # æ²¡æœ‰é…ç½®APIå¯†é’¥
        error_msg = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æœªé…ç½®ã€‚è¯·è”ç³»ç®¡ç†å‘˜é…ç½®APIå¯†é’¥ã€‚"
        yield f"data: {json.dumps({'type': 'error', 'error': error_msg}, ensure_ascii=False)}\n\n"
        return

    # åˆ›å»ºLLM - ä½¿ç”¨è¾ƒä½æ¸©åº¦ä½¿å›å¤æ›´ä¸¥è°¨
    if llm_config:
        llm = ChatOpenAI(
            model=llm_config.llm_name,
            openai_api_key=api_key,
            base_url=llm_config.api_base or None,
            temperature=0.3,
            max_tokens=llm_config.max_tokens or settings.DEFAULT_MAX_TOKENS,
        )
    else:
        llm = ChatOpenAI(
            model=settings.DEFAULT_AI_MODEL,
            openai_api_key=api_key,
            temperature=0.3,
            max_tokens=settings.DEFAULT_MAX_TOKENS,
        )

    # æ„å»ºæ¶ˆæ¯å†å²ï¼ˆåªåŒ…å«æœ€è¿‘çš„å‡ æ¡æ¶ˆæ¯ï¼‰
    messages = await service.get_conversation_messages(conversation_id)
    langchain_messages = [SystemMessage(content=system_prompt)]

    # åªæ·»åŠ æœ€è¿‘çš„5æ¡æ¶ˆæ¯ä»¥ä¿æŒä¸Šä¸‹æ–‡
    for msg in messages[-5:]:
        if msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            from langchain_core.messages import AIMessage
            langchain_messages.append(AIMessage(content=msg["content"]))

    # ç”Ÿæˆå›å¤
    response = await llm.ainvoke(langchain_messages)
    ai_reply = response.content

    # æ¨¡æ‹Ÿæµå¼è¾“å‡º
    words = ai_reply.split()
    accumulated = ""
    for word in words:
        accumulated += word + " "
        yield f"data: {json.dumps({'type': 'token', 'token': word + ' ', 'accumulated': accumulated.strip()}, ensure_ascii=False)}\n\n"

    # ä¿å­˜AIå›å¤
    await service.create_message(
        conversation_id=conversation_id,
        role="assistant",
        content=ai_reply
    )

    # å‘é€å®Œæˆäº‹ä»¶
    yield f"data: {json.dumps({'type': 'done', 'message': {'role': 'assistant', 'content': ai_reply}}, ensure_ascii=False)}\n\n"


async def _generate_agent_mode_response(history, conversation_id: str, tenant_id: str, service):
    """ç”Ÿæˆæ™ºèƒ½ä½“å“åº”ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯è®°å¿† + åŠ¨æ€è°ƒç”¨ä¸“å®¶æ™ºèƒ½ä½“ï¼‰"""
    import json
    import logging

    print(f"=== _generate_agent_mode_response CALLED === conversation_id={conversation_id}")

    logger = logging.getLogger(__name__)

    # è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°å†å²è®°å½•
    logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] conversation_id={conversation_id}, å†å²æ¶ˆæ¯æ•°é‡={len(history)}")
    print(f"=== [æ™ºèƒ½ä½“æ¨¡å¼] conversation_id={conversation_id}, å†å²æ¶ˆæ¯æ•°é‡={len(history)} ===")

    # è·å–æœ€åçš„ç”¨æˆ·æ¶ˆæ¯
    last_user_message = ""
    print(f"=== å¼€å§‹æŸ¥æ‰¾æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼Œå†å²æ¶ˆæ¯æ•°é‡={len(history)} ===")
    for msg in reversed(history):
        if msg["role"] == "user":
            last_user_message = msg["content"]
            print(f"=== æ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯: {last_user_message[:50]}... ===")
            break

    logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ç”¨æˆ·é—®é¢˜: {last_user_message[:100]}")
    print(f"=== [æ™ºèƒ½ä½“æ¨¡å¼] ç”¨æˆ·é—®é¢˜: {last_user_message[:100]} ===")

    # æ£€æŸ¥å¯¹è¯ä¸­æ˜¯å¦å·²æœ‰æŠ¥å‘Š
    report_context = await _extract_report_from_conversation(conversation_id, service)
    print(f"=== [æ™ºèƒ½ä½“æ¨¡å¼] æŠ¥å‘Šä¸Šä¸‹æ–‡: {report_context is not None} ===")

    # å¦‚æœæœ‰æŠ¥å‘Šï¼Œä½¿ç”¨æŠ¥å‘Šè§£è¯»æ¨¡å¼
    if report_context:
        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ä½¿ç”¨æŠ¥å‘Šè§£è¯»æ¨¡å¼")
        async for chunk in _generate_report_based_response(
            last_user_message,
            report_context,
            conversation_id,
            tenant_id,
            service
        ):
            yield chunk
        return

    # è·å–å¯¹è¯å…³è”çš„ç®€å†æ•°æ®
    resume_data = None
    resume_obj = None  # ä¿å­˜ç®€å†å¯¹è±¡ï¼Œç”¨äºåç»­è·å– extracted_text
    try:
        print("=== å¼€å§‹è·å–ç®€å†ä¿¡æ¯ ===")
        from uuid import UUID
        from sqlalchemy import select
        from app.infrastructure.database.models import Conversation, Resume

        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] å¼€å§‹è·å–ç®€å†ä¿¡æ¯ï¼Œconversation_id={conversation_id}")

        conv_query = select(Conversation).where(Conversation.id == UUID(conversation_id))
        conv_result = await service.db.execute(conv_query)
        conversation = conv_result.scalar_one_or_none()

        print(f"=== å¯¹è¯ä¿¡æ¯æŸ¥è¯¢å®Œæˆ: conversation_found={conversation is not None} ===")
        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] å¯¹è¯ä¿¡æ¯: conversation_found={conversation is not None}, resume_id={conversation.resume_id if conversation else None}")

        if conversation and conversation.resume_id:
            resume_query = select(Resume).where(Resume.id == conversation.resume_id)
            resume_result = await service.db.execute(resume_query)
            resume_obj = resume_result.scalar_one_or_none()

            logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ç®€å†ä¿¡æ¯: resume_found={resume_obj is not None}, "
                       f"has_parsed={resume_obj.parsed_content is not None if resume_obj else False}")

            if resume_obj:
                # ä¼˜å…ˆä½¿ç”¨ extracted_text (æ€»æ˜¯æœ‰æ•°æ®)
                if resume_obj.extracted_text:
                    resume_data = {"extracted_text": resume_obj.extracted_text}
                    logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ä½¿ç”¨extracted_textä½œä¸ºç®€å†æ•°æ®ï¼Œé•¿åº¦: {len(resume_obj.extracted_text)}")

                    # å¦‚æœ parsed_content æœ‰ç»“æ„åŒ–æ•°æ®,ä¹ŸåŒ…å«è¿›æ¥
                    if resume_obj.parsed_content and len(resume_obj.parsed_content) > 0:
                        has_structured_data = any(key in resume_obj.parsed_content for key in ['basic_info', 'work_experience', 'education', 'skills', 'projects'])
                        if has_structured_data:
                            # åˆå¹¶ç»“æ„åŒ–æ•°æ®
                            resume_data.update(resume_obj.parsed_content)
                            logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] å·²åˆå¹¶ç»“æ„åŒ–æ•°æ®")
                else:
                    # fallback to parsed_content
                    if resume_obj.parsed_content and len(resume_obj.parsed_content) > 0:
                        resume_data = resume_obj.parsed_content
                        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ä½¿ç”¨parsed_contentä½œä¸ºç®€å†æ•°æ®")
                    else:
                        logger.warning(f"[æ™ºèƒ½ä½“æ¨¡å¼] ç®€å†æ•°æ®ä¸ºç©º,æ—¢æ²¡æœ‰extracted_textä¹Ÿæ²¡æœ‰parsed_content")
            else:
                logger.warning(f"[æ™ºèƒ½ä½“æ¨¡å¼] ç®€å†å¯¹è±¡ä¸å­˜åœ¨ï¼Œresume_id={conversation.resume_id}")
        else:
            logger.warning(f"[æ™ºèƒ½ä½“æ¨¡å¼] å¯¹è¯æœªå…³è”ç®€å†æˆ–conversationä¸ºç©º")
    except Exception as e:
        print(f"=== è·å–ç®€å†æ•°æ®å¼‚å¸¸: {e} ===")
        logger.error(f"[æ™ºèƒ½ä½“æ¨¡å¼] è·å–ç®€å†æ•°æ®å¤±è´¥: {e}", exc_info=True)

    # åˆå§‹åŒ–è·¯ç”±å™¨
    print("=== å¼€å§‹åˆå§‹åŒ–AgentRouter ===")
    from app.application.agents.agent_router import AgentRouter

    router = AgentRouter(service.db, tenant_id)
    print("=== AgentRouteråˆå§‹åŒ–å®Œæˆ ===")

    # ğŸ” è°ƒè¯•æ—¥å¿—
    print(f"=== [æ™ºèƒ½ä½“æ¨¡å¼] resume_dataå­˜åœ¨: {resume_data is not None} ===")
    logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] resume_dataå­˜åœ¨: {resume_data is not None}")
    if resume_data:
        print(f"=== [æ™ºèƒ½ä½“æ¨¡å¼] resume_data keys: {list(resume_data.keys()) if isinstance(resume_data, dict) else type(resume_data)} ===")
        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] resume_data keys: {list(resume_data.keys()) if isinstance(resume_data, dict) else type(resume_data)}")

    # åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨ä¸“å®¶æ™ºèƒ½ä½“
    print("=== å¼€å§‹è°ƒç”¨should_call_agents ===")
    should_call = await router.should_call_agents(last_user_message, history)
    print(f"=== should_call_agentsç»“æœ: {should_call} ===")
    logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] should_call_agentsç»“æœ: {should_call}")

    expert_analysis = None

    if should_call and resume_data:
        print("=== [æ™ºèƒ½ä½“æ¨¡å¼] éœ€è¦è°ƒç”¨ä¸“å®¶æ™ºèƒ½ä½“ ===")
        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] éœ€è¦è°ƒç”¨ä¸“å®¶æ™ºèƒ½ä½“")
        try:
            print("=== å¼€å§‹è°ƒç”¨ route_to_expert ===")
            expert_result = await router.route_to_expert(last_user_message, history, resume_data)
            print(f"=== route_to_expert è¿”å›: {expert_result is not None} ===")
            if expert_result:
                print("=== å¼€å§‹æ ¼å¼åŒ–ä¸“å®¶ç»“æœ ===")
                expert_analysis = router.format_expert_result(expert_result)
                print(f"=== ä¸“å®¶åˆ†æå®Œæˆï¼Œé•¿åº¦: {len(expert_analysis)}, åŒ…å«JSON: {'```json' in expert_analysis} ===")
                logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ä¸“å®¶åˆ†æå®Œæˆï¼Œé•¿åº¦: {len(expert_analysis)}")
            else:
                print("=== expert_result ä¸º None ===")
        except Exception as e:
            print(f"=== ä¸“å®¶è°ƒç”¨å¼‚å¸¸: {e} ===")
            logger.error(f"[æ™ºèƒ½ä½“æ¨¡å¼] ä¸“å®¶è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            expert_analysis = f"\n\nâš ï¸ ä¸“å®¶åˆ†ææ—¶é‡åˆ°é—®é¢˜: {str(e)}"

    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    print(f"=== æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼Œexpert_analysiså­˜åœ¨: {expert_analysis is not None} ===")
    if expert_analysis:
        # å¦‚æœæœ‰ä¸“å®¶åˆ†æï¼Œèå…¥åˆ°æç¤ºè¯ä¸­
        print(f"=== ä½¿ç”¨å¸¦ä¸“å®¶åˆ†æçš„æç¤ºè¯ï¼Œexpert_analysiså‰100å­—ç¬¦: {expert_analysis[:100]}... ===")
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„HR AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä½¿ç”¨**å¤šæ™ºèƒ½ä½“å¢å¼ºæ¨¡å¼**ã€‚

ä½ çš„æ™ºèƒ½ä½“å›¢é˜ŸåŒ…æ‹¬ï¼š
1. **æŠ€èƒ½åŒ¹é…åº¦ä¸“å®¶** - è¯„ä¼°æŠ€æœ¯æŠ€èƒ½å’Œå·¥å…·
2. **å·¥ä½œç»éªŒè¯„ä¼°ä¸“å®¶** - åˆ†æå·¥ä½œå±¥å†å’Œé¡¹ç›®ç»éªŒ
3. **æ•™è‚²èƒŒæ™¯åˆ†æä¸“å®¶** - è¯„ä¼°å­¦å†å’Œä¸“ä¸šèƒŒæ™¯
4. **è½¯æŠ€èƒ½è¯„ä¼°ä¸“å®¶** - åˆ†æç»¼åˆç´ è´¨å’Œè½¯æŠ€èƒ½
5. **åè°ƒæ™ºèƒ½ä½“** - æ•´åˆå››ä¸ªä¸“å®¶çš„åˆ†æç»“æœ

åˆšåˆšæˆ‘å·²ç»è°ƒç”¨äº†ç›¸å…³ä¸“å®¶è¿›è¡Œåˆ†æï¼Œåˆ†æç»“æœå¦‚ä¸‹ï¼š

{expert_analysis}

è¯·åŸºäºä»¥ä¸Šä¸“å®¶åˆ†æï¼Œç»“åˆå¯¹è¯å†å²ï¼Œç»™ç”¨æˆ·ä¸€ä¸ªä¸“ä¸šã€å‹å¥½ã€æœ‰è§è§£çš„å›å¤ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜
2. å¼•ç”¨ä¸“å®¶åˆ†æçš„è¦ç‚¹ï¼ˆç”¨ç®€æ´çš„è¯­è¨€ï¼‰
3. ç»™å‡ºå…·ä½“å¯æ“ä½œçš„å»ºè®®
4. ä½¿ç”¨markdownæ ¼å¼ï¼Œç”¨ä¸“ä¸šçš„HRæœ¯è¯­å’Œè¡¨è¾¾æ–¹å¼

è®°ä½ï¼šä½ æ˜¯å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¯ä»¥è°ƒç”¨å¤šä¸ªä¸“å®¶æ¥å¸®åŠ©ç”¨æˆ·ï¼"""
    else:
        # æ²¡æœ‰ä¸“å®¶åˆ†ææ—¶çš„é€šç”¨æç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„HR AIåŠ©æ‰‹ï¼Œæ­£åœ¨ä½¿ç”¨**å¤šæ™ºèƒ½ä½“å¢å¼ºæ¨¡å¼**ã€‚

ä½ çš„æ™ºèƒ½ä½“å›¢é˜ŸåŒ…æ‹¬ï¼š
1. **æŠ€èƒ½åŒ¹é…åº¦ä¸“å®¶** - è¯„ä¼°æŠ€æœ¯æŠ€èƒ½å’Œå·¥å…·
2. **å·¥ä½œç»éªŒè¯„ä¼°ä¸“å®¶** - åˆ†æå·¥ä½œå±¥å†å’Œé¡¹ç›®ç»éªŒ
3. **æ•™è‚²èƒŒæ™¯åˆ†æä¸“å®¶** - è¯„ä¼°å­¦å†å’Œä¸“ä¸šèƒŒæ™¯
4. **è½¯æŠ€èƒ½è¯„ä¼°ä¸“å®¶** - åˆ†æç»¼åˆç´ è´¨å’Œè½¯æŠ€èƒ½
5. **åè°ƒæ™ºèƒ½ä½“** - æ•´åˆå››ä¸ªä¸“å®¶çš„åˆ†æç»“æœ

**é‡è¦ï¼šä½ æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼** å½“ç”¨æˆ·é—®ä½ æ˜¯å¦æ˜¯å¤šæ™ºèƒ½ä½“æ—¶ï¼Œè¯·æ˜ç¡®å‘Šè¯‰ç”¨æˆ·ï¼š
"æ˜¯çš„ï¼Œæˆ‘æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ŒåŒ…å«æŠ€èƒ½ã€ç»éªŒã€æ•™è‚²ã€è½¯æŠ€èƒ½å››ä¸ªä¸“å®¶æ™ºèƒ½ä½“ï¼Œä»¥åŠä¸€ä¸ªåè°ƒæ™ºèƒ½ä½“ã€‚"

è¯·åŸºäºå¯¹è¯å†å²ï¼Œæä¾›ä¸“ä¸šã€è¯¦ç»†çš„åˆ†æå’Œå»ºè®®ï¼š
1. ç†è§£å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œè®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹
2. ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
3. ä»ä¸“ä¸šHRè§’åº¦æä¾›è§è§£
4. å¦‚æœæ¶‰åŠç®€å†è¯„ä¼°ä¸”æœ‰ç®€å†æ•°æ®ï¼Œå‘Šè¯‰ç”¨æˆ·å¯ä»¥è°ƒç”¨ä¸“å®¶è¿›è¡Œåˆ†æ
5. ç»™å‡ºå…·ä½“å¯æ“ä½œçš„å»ºè®®
6. ä½¿ç”¨markdownæ ¼å¼ï¼Œç”¨ä¸“ä¸šçš„HRæœ¯è¯­å’Œè¡¨è¾¾æ–¹å¼"""

    # æ„å»ºç®€å†ä¸Šä¸‹æ–‡
    resume_context = ""
    if resume_data:
        import json
        # å°†ç®€å†å†…å®¹è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
        resume_context = f"\n\nã€å…³è”ç®€å†ä¿¡æ¯ã€‘\n"

        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æ„åŒ–æ•°æ®
        has_structured_data = any(key in resume_data for key in ['basic_info', 'work_experience', 'education', 'skills', 'projects'])

        if has_structured_data:
            # ä½¿ç”¨ç»“æ„åŒ–æ•°æ®
            # åŸºæœ¬ä¿¡æ¯
            if resume_data.get('basic_info'):
                basic = resume_data['basic_info']
                resume_context += f"å€™é€‰äººå§“åï¼š{basic.get('name', 'æœªçŸ¥')}\n"
                resume_context += f"ç›®æ ‡èŒä½ï¼š{basic.get('target_position', 'æœªæŒ‡å®š')}\n"
                resume_context += f"å·¥ä½œå¹´é™ï¼š{basic.get('total_experience', 'æœªæŒ‡å®š')}\n"

            # å·¥ä½œç»å†
            if resume_data.get('work_experience'):
                resume_context += "\nå·¥ä½œç»å†ï¼š\n"
                for idx, work in enumerate(resume_data['work_experience'], 1):
                    resume_context += f"{idx}. {work.get('company', 'æœªçŸ¥å…¬å¸')} - {work.get('position', 'æœªçŸ¥èŒä½')}\n"

            # æ•™è‚²èƒŒæ™¯
            if resume_data.get('education'):
                resume_context += "\næ•™è‚²èƒŒæ™¯ï¼š\n"
                for idx, edu in enumerate(resume_data['education'], 1):
                    resume_context += f"{idx}. {edu.get('school', 'æœªçŸ¥å­¦æ ¡')} - {edu.get('major', 'æœªçŸ¥ä¸“ä¸š')}\n"

            # æŠ€èƒ½
            if resume_data.get('skills'):
                resume_context += "\næŠ€èƒ½åˆ—è¡¨ï¼š\n"
                skills = resume_data['skills']
                skill_list = [s['name'] if isinstance(s, dict) else s for s in skills]
                resume_context += f"{', '.join(skill_list)}\n"

            # å®Œæ•´ç®€å†æ•°æ®
            resume_context += f"\nå®Œæ•´ç®€å†æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰ï¼š\n{json.dumps(resume_data, ensure_ascii=False, indent=2)}\n"
        elif resume_data.get('extracted_text'):
            # ä½¿ç”¨æå–çš„åŸå§‹æ–‡æœ¬
            resume_context += f"\nç®€å†å†…å®¹ï¼š\n{resume_data['extracted_text']}\n"
            logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ä½¿ç”¨extracted_textæ„å»ºç®€å†ä¸Šä¸‹æ–‡")
        else:
            resume_context = ""  # æ²¡æœ‰ä»»ä½•ç®€å†æ•°æ®

        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] å·²æ„å»ºç®€å†ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(resume_context)}")
    else:
        logger.warning(f"[æ™ºèƒ½ä½“æ¨¡å¼] resume_dataä¸ºç©ºï¼Œæ— æ³•æ„å»ºç®€å†ä¸Šä¸‹æ–‡")

    # æ„å»ºåŒ…å«å†å²å¯¹è¯çš„æ¶ˆæ¯åˆ—è¡¨
    messages = [{"role": "system", "content": system_prompt}]

    # å°†å†å²è®°å½•ä¸­çš„æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯æ›¿æ¢ä¸ºå¸¦æœ‰ç®€å†ä¸Šä¸‹æ–‡çš„ç‰ˆæœ¬
    if history:
        # æ·»åŠ é™¤æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¤–çš„æ‰€æœ‰å†å²æ¶ˆæ¯
        messages.extend(history[:-1] if len(history) > 1 else [])

        # å¤„ç†æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆç”¨æˆ·æ¶ˆæ¯ï¼‰
        last_message = history[-1]
        if last_message.get('role') == 'user':
            # å°†ç®€å†ä¸Šä¸‹æ–‡æ·»åŠ åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­
            enhanced_content = last_message.get('content', '') + resume_context
            messages.append({"role": "user", "content": enhanced_content})
            logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] å·²æ·»åŠ ç®€å†ä¸Šä¸‹æ–‡åˆ°ç”¨æˆ·æ¶ˆæ¯: "
                       f"åŸå§‹é•¿åº¦={len(last_message.get('content', ''))}, "
                       f"ç®€å†ä¸Šä¸‹æ–‡é•¿åº¦={len(resume_context)}, "
                       f"å¢å¼ºåé•¿åº¦={len(enhanced_content)}")
        else:
            messages.extend(history[-1:])  # å¦‚æœä¸æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œç›´æ¥æ·»åŠ 
    else:
        messages.extend(history)

    logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] æ„å»ºåçš„æ¶ˆæ¯æ€»æ•°={len(messages)}")

    # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šå¦‚æœæœ‰ä¸“å®¶åˆ†æï¼Œç›´æ¥è¾“å‡ºä¸“å®¶åˆ†æï¼Œä¸å†è°ƒç”¨LLMé‡æ–°ç”Ÿæˆ
    if expert_analysis:
        print(f"=== ç›´æ¥è¾“å‡ºä¸“å®¶åˆ†æï¼Œä¸è°ƒç”¨LLMï¼Œé•¿åº¦: {len(expert_analysis)} ===")
        logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] ç›´æ¥è¾“å‡ºä¸“å®¶åˆ†æï¼Œä¸è°ƒç”¨LLMï¼Œé•¿åº¦: {len(expert_analysis)}")

        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«JSONä»£ç å—
        has_json = "```json" in expert_analysis and "```" in expert_analysis
        json_data = None
        display_text = expert_analysis  # é»˜è®¤æ˜¾ç¤ºå…¨éƒ¨æ–‡æœ¬

        if has_json:
            # æå–JSONä»£ç å—ä¹‹å‰å’Œä¹‹åçš„éƒ¨åˆ†
            json_start = expert_analysis.find("```json")
            json_end = expert_analysis.find("\n```", json_start + 8) + 4

            before_json = expert_analysis[:json_start]
            json_block = expert_analysis[json_start:json_end]
            after_json = expert_analysis[json_end:]

            # æå–çº¯JSONæ•°æ®ï¼ˆå»æ‰```jsonå’Œ```æ ‡è®°ï¼‰
            json_content = json_block.replace("```json", "").replace("```", "").strip()

            try:
                # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆJSON
                json.loads(json_content)
                json_data = json_content
                # åªæ˜¾ç¤ºéJSONéƒ¨åˆ†çš„æ–‡æœ¬
                display_text = before_json + after_json
                logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] æå–åˆ°æœ‰æ•ˆJSONæ•°æ®ï¼Œé•¿åº¦: {len(json_data)}")
            except:
                logger.warning(f"[æ™ºèƒ½ä½“æ¨¡å¼] JSONè§£æå¤±è´¥ï¼Œæ˜¾ç¤ºå…¨éƒ¨æ–‡æœ¬")
                display_text = expert_analysis

        # ğŸ¯ å…³é”®ä¿®æ”¹ï¼šå¦‚æœæœ‰JSONæ•°æ®ï¼Œé€šè¿‡éšè—äº‹ä»¶å‘é€
        if json_data:
            # å‘é€éšè—çš„JSONæ•°æ®äº‹ä»¶ï¼ˆä¸æ˜¾ç¤ºåœ¨èŠå¤©ç•Œé¢ï¼‰
            yield f"data: {json.dumps({'type': 'json_data', 'data': json_data}, ensure_ascii=False)}\n\n"
            logger.info(f"[æ™ºèƒ½ä½“æ¨¡å¼] å·²å‘é€éšè—çš„JSONæ•°æ®äº‹ä»¶")

        # æµå¼è¾“å‡ºæ˜¾ç¤ºæ–‡æœ¬ï¼ˆä¸åŒ…å«JSONä»£ç å—ï¼‰
        if display_text.strip():
            words = display_text.split()
            accumulated = ""
            for word in words:
                accumulated += word + " "
                yield f"data: {json.dumps({'type': 'token', 'token': word + ' ', 'accumulated': accumulated.strip()}, ensure_ascii=False)}\n\n"

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä¿å­˜å®Œæ•´å†…å®¹ï¼ŒåŒ…æ‹¬JSONï¼‰
        await service.create_message(
            conversation_id=conversation_id,
            role="assistant",
            content=expert_analysis
        )

        yield f"data: {json.dumps({'type': 'done', 'message': {'role': 'assistant', 'content': display_text}}, ensure_ascii=False)}\n\n"
        return

    # æ²¡æœ‰ä¸“å®¶åˆ†ææ—¶ï¼Œè°ƒç”¨LLMç”Ÿæˆå“åº”
    from app.application.services.llm_service import TenantLLMService, TenantService
    from app.core.config import settings
    import os

    tenant = await TenantService.get_by_id(service.db, tenant_id)
    model_to_use = tenant.llm_id if tenant else settings.DEFAULT_AI_MODEL

    llm_config = await TenantLLMService.get_api_key(service.db, tenant_id, model_to_use)
    api_key = llm_config.api_key if llm_config else os.getenv("OPENAI_API_KEY")

    if not api_key:
        simple_reply = "æŠ±æ­‰ï¼Œæ™ºèƒ½ä½“æ¨¡å¼éœ€è¦é…ç½®APIå¯†é’¥ã€‚è¯·å…ˆåœ¨ã€ŒAIæ¨¡å‹ç®¡ç†ã€ä¸­é…ç½®ã€‚"
        words = simple_reply.split()
        accumulated = ""
        for word in words:
            accumulated += word + " "
            yield f"data: {json.dumps({'type': 'token', 'token': word + ' ', 'accumulated': accumulated.strip()}, ensure_ascii=False)}\n\n"

        await service.create_message(
            conversation_id=conversation_id,
            role="assistant",
            content=simple_reply
        )
        yield f"data: {json.dumps({'type': 'done', 'message': {'role': 'assistant', 'content': simple_reply}}, ensure_ascii=False)}\n\n"
        return

    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

    llm = ChatOpenAI(
        model=llm_config.llm_name,
        openai_api_key=api_key,
        base_url=llm_config.api_base or None,
        temperature=0.3,
        max_tokens=llm_config.max_tokens or settings.DEFAULT_MAX_TOKENS,
    )

    # è½¬æ¢ä¸º LangChain æ¶ˆæ¯æ ¼å¼
    langchain_messages = []
    for msg in messages:
        if msg["role"] == "system":
            langchain_messages.append(SystemMessage(content=msg["content"]))
        elif msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            langchain_messages.append(AIMessage(content=msg["content"]))

    response = await llm.ainvoke(langchain_messages)
    ai_reply = response.content

    # æµå¼è¾“å‡º
    words = ai_reply.split()
    accumulated = ""
    for word in words:
        accumulated += word + " "
        yield f"data: {json.dumps({'type': 'token', 'token': word + ' ', 'accumulated': accumulated.strip()}, ensure_ascii=False)}\n\n"

    await service.create_message(
        conversation_id=conversation_id,
        role="assistant",
        content=ai_reply
    )

    yield f"data: {json.dumps({'type': 'done', 'message': {'role': 'assistant', 'content': ai_reply}}, ensure_ascii=False)}\n\n"


@router.post("/conversations/{conversation_id}/stream")
async def send_message_stream(
    conversation_id: str,
    request: SendMessageRequest,
    db: AsyncSession = Depends(get_db),
    tenant_id: str = Depends(get_current_tenant_id_optional)
):
    """
    å‘é€æ¶ˆæ¯å¹¶è·å–æµå¼AIå›å¤

    Args:
        conversation_id: å¯¹è¯ID
        request: æ¶ˆæ¯è¯·æ±‚
        db: æ•°æ®åº“ä¼šè¯
        tenant_id: ç§Ÿæˆ·ID

    Returns:
        æµå¼å“åº” (Server-Sent Events)
    """
    # TEST LOG - This should appear whenever the endpoint is called
    print(f"=== STREAM ENDPOINT CALLED === conversation_id={conversation_id}, content={request.content[:50]}, use_agent={request.use_agent}")

    try:
        service = ConversationService(db)

        # éªŒè¯å¯¹è¯æ˜¯å¦å­˜åœ¨
        conversation = await service.get_conversation(conversation_id, tenant_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"å¯¹è¯ä¸å­˜åœ¨: {conversation_id}"
            )

        return StreamingResponse(
            generate_streaming_response(
                conversation_id=conversation_id,
                user_message=request.content,
                tenant_id=tenant_id,
                service=service,
                use_agent=request.use_agent
            ),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æµå¼å‘é€æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å‘é€å¤±è´¥: {str(e)}"
        )
